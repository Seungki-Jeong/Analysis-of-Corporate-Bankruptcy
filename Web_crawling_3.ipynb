{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "from bs4 import BeautifulSoup\n",
    "from konlpy.tag import Hannanum, Okt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수집\n",
    "def search(name_list, ds, de):\n",
    "    baseUrl = 'https://search.naver.com/search.naver?&where=news&query='\n",
    "    url = baseUrl + urllib.parse.quote_plus(name_list) \n",
    "    html = urllib.request.urlopen(url).read()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    subject = []\n",
    "    date = []\n",
    "    contents = []\n",
    "    company = []\n",
    "    \n",
    "    page = 1\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        url = baseUrl + urllib.parse.quote_plus(name_list) + '&nso=so%3Ar%2Cp%3Afrom'+ str(ds) + 'to' + str(de) +'&start=' + str(page)\n",
    "        html = urllib.request.urlopen(url).read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        word = soup.find_all(class_='type01')[0]\n",
    "        word = word.find_all('dl')\n",
    "\n",
    "        title = soup.find_all(class_='_sp_each_title')\n",
    "\n",
    "        com = soup.find_all(class_='_sp_each_source')\n",
    "\n",
    "        date_re = re.compile(r'\\d\\d\\d\\d.\\d\\d.\\d\\d.')\n",
    "        day = soup.find_all(class_='txt_inline')\n",
    "\n",
    "\n",
    "        # 컨텐츠\n",
    "        for words in word:\n",
    "            contents.append(words.find_all('dd')[1].get_text())\n",
    "\n",
    "        # 타이틀\n",
    "        for tie in title:\n",
    "            subject.append(tie.get_text())\n",
    "\n",
    "        # 업체\n",
    "        for coms in com:\n",
    "            if coms.get_text()[-2:] == '선정':\n",
    "                company.append(coms.get_text()[:-6])\n",
    "            else:\n",
    "                company.append(coms.get_text())\n",
    "\n",
    "        # 시간\n",
    "        for dates in day:\n",
    "            try:\n",
    "                match = date_re.search(dates.get_text())\n",
    "                date.append(match.group())\n",
    "            except:\n",
    "                date_re2 = re.compile(r'\\d')\n",
    "                match = date_re2.search(dates.get_text())\n",
    "                m = int(match.group())\n",
    "                year = str(datetime.datetime.today().year)\n",
    "                month = str(datetime.datetime.today().month)\n",
    "                day = str(datetime.datetime.today().day-m)\n",
    "                result = year + '.' + month + '.' + day + '.'\n",
    "                date.append(result)\n",
    "        \n",
    "        print(page, end=' ')\n",
    "        \n",
    "        try:\n",
    "            if soup.find_all(class_='next')[0].get_text() != '다음페이지':\n",
    "                break\n",
    "            else: \n",
    "                page += 10\n",
    "        except:\n",
    "            if soup.find(class_='next') != '다음페이지':\n",
    "                break\n",
    "\n",
    "    df = pd.DataFrame(list(zip(subject, date, contents, company)), columns = ['title', 'date','contents', 'company'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 2\n",
    "def sentence(df):\n",
    "    \n",
    "    df['contents'] = df['contents'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣]\",\" \")\n",
    "    \n",
    "    stopwords = ['을', '로', '의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다''의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "    okt = Okt()\n",
    "    \n",
    "    contents = []\n",
    "\n",
    "    for sentence in tqdm(df['contents']):\n",
    "        temp_x = []\n",
    "        temp_x = okt.nouns(sentence)\n",
    "        temp_x = [word for word in temp_x if not word in stopwords]\n",
    "        contents.append(temp_x)\n",
    "        \n",
    "    return contents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 빈도수\n",
    "def word_count(contents, name):\n",
    "    wordlist = sum(contents, [])\n",
    "    word_list = pd.Series(wordlist)\n",
    "    result = word_list.value_counts()\n",
    "    result.to_csv('data/기업 '+name+'.csv', mode='w')\n",
    "    print(name + ' Save compelte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(index=range(0,0), columns=['title', 'date','contents', 'company'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_list = pd.read_csv('data/com_list2.csv')\n",
    "com_list['ds'] = [date - 10000 for date in com_list['date']]\n",
    "com_list.rename(columns = {'date' : 'de'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>de</th>\n",
       "      <th>ds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VK</td>\n",
       "      <td>20060722</td>\n",
       "      <td>20050722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>텔슨전자</td>\n",
       "      <td>20040810</td>\n",
       "      <td>20030810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이론테크</td>\n",
       "      <td>20030430</td>\n",
       "      <td>20020430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>코리아링크</td>\n",
       "      <td>20030416</td>\n",
       "      <td>20020416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>소프트윈</td>\n",
       "      <td>20021128</td>\n",
       "      <td>20011128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company        de        ds\n",
       "0      VK  20060722  20050722\n",
       "1    텔슨전자  20040810  20030810\n",
       "2    이론테크  20030430  20020430\n",
       "3   코리아링크  20030416  20020416\n",
       "4    소프트윈  20021128  20011128"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_de = com_list['de'].tolist()\n",
    "com_ds = com_list['ds'].tolist()\n",
    "com_list = com_list['company'].tolist()\n",
    "# com_list['company'] = [cmp_lst.strip() for cmp_lst in com_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'com_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-29b6f2ca6c2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mcmp_lst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mde\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcom_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcom_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcom_de\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmp_lst\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' Start'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' ds'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m' de'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mde\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmp_lst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mde\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'com_list' is not defined"
     ]
    }
   ],
   "source": [
    "for cmp_lst, ds, de in zip(com_list, com_ds, com_de):\n",
    "    print(cmp_lst + ' Start' + ' ds' + str(ds) +' de' + str(de))\n",
    "    try:\n",
    "        df = search(cmp_lst, ds, de)\n",
    "    except:\n",
    "        continue \n",
    "        \n",
    "    df_contents = sentence(df)\n",
    "    word_count(df_contents, cmp_lst)\n",
    "    result = pd.concat([result, df])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-fe4ece933f36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/test.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "result.to_csv('data/네이버 기사.csv', mode='w', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VK', '텔슨전자', '이론테크', '코리아링크', '소프트윈']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 11 21 31 41 51 61 71 81 91 101 111 121 131 141 151 161 171 181 191 201 211 221 231 241 251 261 271 281 291 301 311 321 331 341 351 361 371 381 391 401 411 421 431 441 451 461 471 481 491 501 511 521 531 541 551 561 571 581 591 601 611 621 631 641 651 661 671 681 691 701 711 721 731 741 751 761 771 781 791 801 811 821 831 841 851 861 871 881 891 901 911 921 931 941 951 961 971 981 991 1001 1011 1021 1031 1041 1051 1061 1071 1081 1091 1101 1111 1121 1131 1141 1151 1161 1171 1181 1191 1201 1211 1221 1231 1241 1251 1261 1271 1281 1291 1301 1311 1321 1331 1341 1351 1361 1371 1381 1391 1401 1411 1421 1431 1441 1451 1461 1471 1481 1491 1501 1511 1521 1531 1541 1551 1561 1571 1581 1591 1601 1611 1621 1631 1641 "
     ]
    }
   ],
   "source": [
    "df = search('VK', 20050722, 20060722)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['contents'] = df['contents'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣]\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['을', '로', '의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다''의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hannanum = Hannanum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e632ac9956486b972cc0c8a2980fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1642.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in tqdm(df['contents']):\n",
    "    temp_x = []\n",
    "    temp_x = okt.nouns(sentence)\n",
    "    temp_x = [word for word in temp_x if not word in stopwords]\n",
    "    contents.append(temp_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VK Save compelte\n"
     ]
    }
   ],
   "source": [
    "word_count(contents, 'VK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
